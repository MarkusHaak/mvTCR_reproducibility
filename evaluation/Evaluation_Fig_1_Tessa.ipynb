{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21932977",
   "metadata": {},
   "source": [
    "# Evaluation Tessa\n",
    "\n",
    "In this notebook, we calculate the performance of Tessa on our datasets. Please run the script tessa_wraper for each dataset before running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5b2f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.environ['R_HOME'] = 'C:/Users/felix.drost/Anaconda3/envs/tessa_evaluation/Lib/R' \n",
    "import rpy2.robjects as rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64c48b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../mvTCR/tcr_embedding/evaluation')\n",
    "\n",
    "from Metrics import get_knn_classification, get_normalized_mutual_information\n",
    "from Metrics import get_silhouette_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42dd925",
   "metadata": {},
   "source": [
    "## Functions for Tessa embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31cbf4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tessa_weights(base_dir):\n",
    "    \"\"\"\n",
    "    Load the b-values from the result RData\n",
    "    :param base_dir: path to the base folder of the experiment\n",
    "    :return: numpy array [3] giving the b-weights\n",
    "    \"\"\"\n",
    "    rob.r['load'](f'{base_dir}/res/tessa_final.RData')\n",
    "    b = rob.r['tessa_results'][0]\n",
    "    b = np.array(b)\n",
    "    return b\n",
    "\n",
    "\n",
    "def get_tessa_unweighted_distances(base_dir):\n",
    "    \"\"\"\n",
    "    Extract the Briseis encoding from file\n",
    "    :param file_dir: path to the base folder of the experiment\n",
    "    :return: numpy array [num_cells, 30] giving the embedding space by Briseis\n",
    "    \"\"\"\n",
    "    unweighted_dist = pd.read_csv(f'{base_dir}/tessa_tcr_embedding.csv', index_col=0)\n",
    "    unweighted_dist = unweighted_dist.values\n",
    "    return unweighted_dist\n",
    "\n",
    "\n",
    "def get_weighted_distances(unweighted_dist, b):\n",
    "    \"\"\"\n",
    "    Calculates the weigthed distance\n",
    "    :param unweighted_dist: numpy array [num_cells, 30] giving the TCR embedding\n",
    "    :param b: numpy array [30] giving the position weights\n",
    "    :return: numpy array [num_cells, 30] giving the weighted embedding\n",
    "    \"\"\"\n",
    "    weighted_dist = unweighted_dist * b\n",
    "    return weighted_dist\n",
    "\n",
    "def calculate_embedding(dataset, split, donor=None, do_atlas=True, do_weighting=True):\n",
    "    suffix = 'atlas' \n",
    "    if not do_atlas:\n",
    "        suffix = 'query'\n",
    "    base_dir = f'../results/tessa/output/{dataset}/'\n",
    "    if donor is not None:\n",
    "        base_dir += f'{donor}/'\n",
    "    base_dir += f'{split}'    \n",
    "    embedding = get_tessa_unweighted_distances(f'{base_dir}/{suffix}')\n",
    "\n",
    "    if do_weighting:\n",
    "        b = get_tessa_weights(f'{base_dir}/atlas')\n",
    "        embedding = get_weighted_distances(embedding, b)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb26914",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d4b98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(split, donor, return_df=False, col='binding_name'):\n",
    "    \"\"\"\n",
    "    Extract the labels from the TCR file\n",
    "    :param donor: id of the 10x donor\n",
    "    :return: list [num_cells], list [num_cells] representing the binding labels for atlas and query set\n",
    "    \"\"\"\n",
    "    path_labels = f'../mvTCR/data/tessa/10x/{donor}/{split}_'\n",
    "    df_atlas = pd.read_csv(path_labels+'tcrs_atlas.csv')\n",
    "    df_query = pd.read_csv(path_labels+'tcrs_query.csv')\n",
    "    if not return_df:\n",
    "        return df_atlas[col].tolist(), df_query[col].tolist()\n",
    "    df_atlas = df_atlas[['contig_id', col]]\n",
    "    df_query = df_query[['contig_id', col]]\n",
    "    \n",
    "    df_atlas = df_atlas.set_index('contig_id')\n",
    "    df_atlas.index.name = None\n",
    "    df_query = df_query.set_index('contig_id')\n",
    "    df_query.index.name = None\n",
    "    return df_atlas, df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b32c295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tessa_clusters(split, donor):\n",
    "    path_file = '../results/tessa/output/'\n",
    "    if donor == 'covid':\n",
    "        path_file += 'covid/'\n",
    "    else:\n",
    "        path_file += f'10x/{donor}/'\n",
    "    path_file += f'{split}/atlas/res/tessa_final.RData'\n",
    "    rob.r['load'](path_file)\n",
    "    clusters = rob.r['tessa_results'][1]\n",
    "\n",
    "    barcodes = list(clusters[0])\n",
    "    group_IDs = list(clusters[1])\n",
    "    cluster_numbers = list(clusters[2])\n",
    "    df_clusters = pd.DataFrame({'barcode': barcodes, 'group_ID': group_IDs, 'cluster_number': cluster_numbers})\n",
    "  \n",
    "    df_clusters['barcode'] = [name.replace('.', '-') for name in df_clusters['barcode']]\n",
    "    df_clusters = df_clusters.set_index('barcode')\n",
    "    df_clusters.index.name = None\n",
    "    df_clusters.columns = ['group', 'cluster']\n",
    "    return df_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5e1b81",
   "metadata": {},
   "source": [
    "## 10x - Donor 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ca1dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_labels = f'../mvTCR/data/tessa/10x/donor_1/split_2_'\n",
    "df_atlas = pd.read_csv(path_labels+'tcrs_atlas.csv')\n",
    "df_query = pd.read_csv(path_labels+'tcrs_query.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d63d024e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass weights=distance as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass weights=distance as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass weights=distance as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass weights=distance as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass weights=distance as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>split</th>\n",
       "      <th>metrics</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tessa</td>\n",
       "      <td>0</td>\n",
       "      <td>Prediction test</td>\n",
       "      <td>0.680058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tessa</td>\n",
       "      <td>0</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.489977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tessa</td>\n",
       "      <td>1</td>\n",
       "      <td>Prediction test</td>\n",
       "      <td>0.807037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tessa</td>\n",
       "      <td>1</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.512067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tessa</td>\n",
       "      <td>2</td>\n",
       "      <td>Prediction test</td>\n",
       "      <td>0.611818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tessa</td>\n",
       "      <td>2</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.535020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tessa</td>\n",
       "      <td>3</td>\n",
       "      <td>Prediction test</td>\n",
       "      <td>0.749910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tessa</td>\n",
       "      <td>3</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.550911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tessa</td>\n",
       "      <td>4</td>\n",
       "      <td>Prediction test</td>\n",
       "      <td>0.212988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tessa</td>\n",
       "      <td>4</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.449310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  split          metrics    scores\n",
       "0  tessa      0  Prediction test  0.680058\n",
       "1  tessa      0              NMI  0.489977\n",
       "2  tessa      1  Prediction test  0.807037\n",
       "3  tessa      1              NMI  0.512067\n",
       "4  tessa      2  Prediction test  0.611818\n",
       "5  tessa      2              NMI  0.535020\n",
       "6  tessa      3  Prediction test  0.749910\n",
       "7  tessa      3              NMI  0.550911\n",
       "8  tessa      4  Prediction test  0.212988\n",
       "9  tessa      4              NMI  0.449310"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = '10x'\n",
    "donor = 'donor_1'\n",
    "\n",
    "model_names = []\n",
    "splits = []\n",
    "metrics = []\n",
    "scores = []\n",
    "\n",
    "for i in range(5):\n",
    "    split = f'split_{i}'\n",
    "    print(split)\n",
    "    \n",
    "    # KNN Evaluation\n",
    "    embedding_atlas = calculate_embedding(dataset, split, donor, do_atlas=True, do_weighting=True)\n",
    "    embedding_query = calculate_embedding(dataset, split, donor, do_atlas=False, do_weighting=True)\n",
    "    \n",
    "    labels_atlas, labels_query = get_labels(split, donor)\n",
    "    \n",
    "    score = get_knn_classification(embedding_atlas, embedding_query, labels_atlas, labels_query)\n",
    "    score = score['weighted avg']['f1-score']\n",
    "    \n",
    "    model_names.append('tessa')\n",
    "    splits.append(i)\n",
    "    metrics.append(f'Prediction test')\n",
    "    scores.append(score)\n",
    "    \n",
    "    # Clustering Evaluation\n",
    "    labels_atlas, _ = get_labels(split, donor, return_df=True)\n",
    "    labels_predicted = get_tessa_clusters(split, donor)\n",
    "    df_full = pd.concat([labels_atlas, labels_predicted], axis=1)\n",
    "    score = get_normalized_mutual_information(df_full['binding_name'], df_full['cluster'])\n",
    "    \n",
    "    model_names.append('tessa')\n",
    "    splits.append(i)\n",
    "    metrics.append(f'NMI')\n",
    "    scores.append(score)\n",
    "    \n",
    "    \n",
    "results_10x_tessa_d1 = {\n",
    "    'model': model_names,\n",
    "    'split': splits,\n",
    "    'metrics': metrics,\n",
    "    'scores': scores,\n",
    "}\n",
    "results_10x_tessa_d1 = pd.DataFrame(results_10x_tessa_d1)\n",
    "results_10x_tessa_d1.to_csv('../results/performance_tessa_10x_donor_1.csv')\n",
    "results_10x_tessa_d1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10448236",
   "metadata": {},
   "source": [
    "## 10x - Donor 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8bad1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass weights=distance as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass weights=distance as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass weights=distance as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass weights=distance as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass weights=distance as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\felix.drost\\Anaconda3\\envs\\tessa_evaluation\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>split</th>\n",
       "      <th>metrics</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tessa</td>\n",
       "      <td>0</td>\n",
       "      <td>Prediction test</td>\n",
       "      <td>0.780243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tessa</td>\n",
       "      <td>0</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.347003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tessa</td>\n",
       "      <td>1</td>\n",
       "      <td>Prediction test</td>\n",
       "      <td>0.624069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tessa</td>\n",
       "      <td>1</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.385786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tessa</td>\n",
       "      <td>2</td>\n",
       "      <td>Prediction test</td>\n",
       "      <td>0.602298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tessa</td>\n",
       "      <td>2</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.372139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tessa</td>\n",
       "      <td>3</td>\n",
       "      <td>Prediction test</td>\n",
       "      <td>0.692135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tessa</td>\n",
       "      <td>3</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.387633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tessa</td>\n",
       "      <td>4</td>\n",
       "      <td>Prediction test</td>\n",
       "      <td>0.496368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tessa</td>\n",
       "      <td>4</td>\n",
       "      <td>NMI</td>\n",
       "      <td>0.421416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  split          metrics    scores\n",
       "0  tessa      0  Prediction test  0.780243\n",
       "1  tessa      0              NMI  0.347003\n",
       "2  tessa      1  Prediction test  0.624069\n",
       "3  tessa      1              NMI  0.385786\n",
       "4  tessa      2  Prediction test  0.602298\n",
       "5  tessa      2              NMI  0.372139\n",
       "6  tessa      3  Prediction test  0.692135\n",
       "7  tessa      3              NMI  0.387633\n",
       "8  tessa      4  Prediction test  0.496368\n",
       "9  tessa      4              NMI  0.421416"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = '10x'\n",
    "donor = 'donor_2'\n",
    "\n",
    "model_names = []\n",
    "splits = []\n",
    "metrics = []\n",
    "scores = []\n",
    "\n",
    "for i in range(5):\n",
    "    split = f'split_{i}'\n",
    "    \n",
    "    # KNN Evaluation\n",
    "    embedding_atlas = calculate_embedding(dataset, split, donor, do_atlas=True, do_weighting=True)\n",
    "    embedding_query = calculate_embedding(dataset, split, donor, do_atlas=False, do_weighting=True)\n",
    "    \n",
    "    labels_atlas, labels_query = get_labels(split, donor)\n",
    "    score = get_knn_classification(embedding_atlas, embedding_query, labels_atlas, labels_query)\n",
    "    score = score['weighted avg']['f1-score']\n",
    "    \n",
    "    model_names.append('tessa')\n",
    "    splits.append(i)\n",
    "    metrics.append(f'Prediction test')\n",
    "    scores.append(score)\n",
    "    \n",
    "    # Clustering Evaluation\n",
    "    labels_atlas, _ = get_labels(split, donor, return_df=True)\n",
    "    labels_predicted = get_tessa_clusters(split, donor)\n",
    "    df_full = pd.concat([labels_atlas, labels_predicted], axis=1)\n",
    "    score = get_normalized_mutual_information(df_full['binding_name'], df_full['cluster'])\n",
    "    \n",
    "    model_names.append('tessa')\n",
    "    splits.append(i)\n",
    "    metrics.append(f'NMI')\n",
    "    scores.append(score)\n",
    "    \n",
    "results_10x_tessa_d2 = {\n",
    "    'model': model_names,\n",
    "    'split': splits,\n",
    "    'metrics': metrics,\n",
    "    'scores': scores,\n",
    "}\n",
    "results_10x_tessa_d2 = pd.DataFrame(results_10x_tessa_d2)\n",
    "results_10x_tessa_d2.to_csv('../results/performance_tessa_10x_donor_2.csv')\n",
    "results_10x_tessa_d2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df33655",
   "metadata": {},
   "source": [
    "## Covid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb48458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_covid(split, return_df=False, col='T_cells'):\n",
    "    path_labels = f'../mvTCR/data/tessa/covid/{split}_'\n",
    "    df_atlas = pd.read_csv(path_labels+'tcrs_atlas.csv')\n",
    "    if not return_df:\n",
    "        return df_atlas[col].tolist()\n",
    "    df_atlas = df_atlas[['contig_id', col]]\n",
    "    \n",
    "    df_atlas = df_atlas.set_index('contig_id')\n",
    "    df_atlas.index.name = None\n",
    "    return df_atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c05785a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>split</th>\n",
       "      <th>metrics</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tessa</td>\n",
       "      <td>0</td>\n",
       "      <td>NMI_cell_type</td>\n",
       "      <td>0.154338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tessa</td>\n",
       "      <td>0</td>\n",
       "      <td>NMI_reactivity</td>\n",
       "      <td>0.074758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tessa</td>\n",
       "      <td>1</td>\n",
       "      <td>NMI_cell_type</td>\n",
       "      <td>0.141279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tessa</td>\n",
       "      <td>1</td>\n",
       "      <td>NMI_reactivity</td>\n",
       "      <td>0.083730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tessa</td>\n",
       "      <td>2</td>\n",
       "      <td>NMI_cell_type</td>\n",
       "      <td>0.145306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tessa</td>\n",
       "      <td>2</td>\n",
       "      <td>NMI_reactivity</td>\n",
       "      <td>0.065588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tessa</td>\n",
       "      <td>3</td>\n",
       "      <td>NMI_cell_type</td>\n",
       "      <td>0.149500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tessa</td>\n",
       "      <td>3</td>\n",
       "      <td>NMI_reactivity</td>\n",
       "      <td>0.060792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tessa</td>\n",
       "      <td>4</td>\n",
       "      <td>NMI_cell_type</td>\n",
       "      <td>0.144616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tessa</td>\n",
       "      <td>4</td>\n",
       "      <td>NMI_reactivity</td>\n",
       "      <td>0.079768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  split         metrics    scores\n",
       "0  tessa      0   NMI_cell_type  0.154338\n",
       "1  tessa      0  NMI_reactivity  0.074758\n",
       "2  tessa      1   NMI_cell_type  0.141279\n",
       "3  tessa      1  NMI_reactivity  0.083730\n",
       "4  tessa      2   NMI_cell_type  0.145306\n",
       "5  tessa      2  NMI_reactivity  0.065588\n",
       "6  tessa      3   NMI_cell_type  0.149500\n",
       "7  tessa      3  NMI_reactivity  0.060792\n",
       "8  tessa      4   NMI_cell_type  0.144616\n",
       "9  tessa      4  NMI_reactivity  0.079768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'covid'\n",
    "\n",
    "model_names = []\n",
    "splits = []\n",
    "metrics = []\n",
    "scores = []\n",
    "\n",
    "for i in range(5):\n",
    "    split = f'split_{i}'\n",
    "    \n",
    "    # Celltype\n",
    "    labels_atlas = get_labels_covid(split, return_df=True, col='T_cells')\n",
    "    labels_predicted = get_tessa_clusters(split, 'covid')\n",
    "    df_full = pd.concat([labels_atlas, labels_predicted], axis=1)\n",
    "    score = get_normalized_mutual_information(df_full['T_cells'], df_full['cluster'])\n",
    "    \n",
    "    model_names.append('tessa')\n",
    "    splits.append(i)\n",
    "    metrics.append(f'NMI_cell_type')\n",
    "    scores.append(score)\n",
    "    \n",
    "    # Reactivity\n",
    "    labels_atlas = get_labels_covid(split, return_df=True, col='reactivity')\n",
    "    labels_predicted = get_tessa_clusters(split, 'covid')\n",
    "    df_full = pd.concat([labels_atlas, labels_predicted], axis=1)\n",
    "    score = get_normalized_mutual_information(df_full['reactivity'], df_full['cluster'])\n",
    "    \n",
    "    model_names.append('tessa')\n",
    "    splits.append(i)\n",
    "    metrics.append(f'NMI_reactivity')\n",
    "    scores.append(score)\n",
    "    \n",
    "results_covid_tessa = {\n",
    "    'model': model_names,\n",
    "    'split': splits,\n",
    "    'metrics': metrics,\n",
    "    'scores': scores,\n",
    "}\n",
    "results_covid_tessa = pd.DataFrame(results_covid_tessa)\n",
    "results_covid_tessa.to_csv('../results/performance_tessa_covid.csv')\n",
    "results_covid_tessa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75a165",
   "metadata": {},
   "source": [
    "## Write to Supplementary Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f7399d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out = '../results/supplement/S1_benchmarking.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(path_out, mode='a') as writer:  \n",
    "    results_10x_tessa_d1.to_excel(writer, sheet_name='tessa_10x_donor1')\n",
    "    results_10x_tessa_d2.to_excel(writer, sheet_name='tessa_10x_donor2')\n",
    "    results_covid_tessa.to_excel(writer, sheet_name='tessa_Covid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tessa_evaluation]",
   "language": "python",
   "name": "conda-env-tessa_evaluation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
